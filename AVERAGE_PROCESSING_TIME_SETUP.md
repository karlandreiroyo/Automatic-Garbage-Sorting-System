# Average Processing Time – Dashboard & Optional Storage

## What the dashboard shows

- **Average Processing Time** is the **average of all** `processing_time` values (in seconds) for the scope shown:
  - **Admin (no collector selected):** average over all waste items from **today**.
  - **Admin (collector selected):** average over waste items from bins assigned to that collector for the selected date.
  - **Superadmin:** average over all waste items for today (or selected scope).

So the number is already an **overall average** for that scope (e.g. “average of all items today”), not “average of averages.”

**Formula:**  
`avg_processing_time = (sum of processing_time for each item) / (number of items)`  
Null/missing `processing_time` is treated as 0.

---

## Should you store it in the database?

| Approach | Pros | Cons |
|----------|------|------|
| **Compute on read (current)** | Always correct, no extra tables, no sync issues | Can be slower if you have a very large number of rows |
| **Store in DB** | Fast dashboard, can keep history (e.g. past days), good for reporting | Need to keep stored value in sync (e.g. when new items are added) |

**Recommendation:**  
- Keep **computing on read** unless the dashboard or reports get slow.  
- If you want **faster loads** or **historical values per day**, add the optional table below and have the backend (or a job) compute and store the value.

---

## Optional: store in Supabase

If you want to store the overall average (e.g. per day) in the database:

### 1. Create the table (run in Supabase SQL Editor)

```sql
-- One row per day: overall average processing time and item count for that day
CREATE TABLE IF NOT EXISTS public.dashboard_daily_stats (
  id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  stat_date date NOT NULL UNIQUE,
  avg_processing_time_seconds numeric(10,2) NOT NULL DEFAULT 0,
  total_items integer NOT NULL DEFAULT 0,
  updated_at timestamptz NOT NULL DEFAULT now()
);

-- Optional: index for fast lookup by date
CREATE INDEX IF NOT EXISTS idx_dashboard_daily_stats_stat_date ON public.dashboard_daily_stats (stat_date);
```

### 2. How to keep it updated

**Option A – When dashboard loads (lazy)**  
Backend endpoint for dashboard stats:

1. For the requested date, compute from `waste_items`:  
   `avg = sum(processing_time) / count(*)`, `total_items = count(*)`.
2. Upsert into `dashboard_daily_stats` for that `stat_date`.
3. Return the computed (or just stored) `avg_processing_time` and `total_items`.

Dashboard keeps calling the same endpoint; first time it computes and stores, next times it can read from `dashboard_daily_stats` for that date if you want.

**Option B – Scheduled job (e.g. daily)**  
A cron or scheduled function runs once per day, computes yesterday’s (or today’s) average from `waste_items`, and upserts into `dashboard_daily_stats`. The dashboard then reads only from this table.

**Option C – Trigger on `waste_items`**  
More complex: trigger on INSERT/UPDATE/DELETE on `waste_items` that recalculates and updates `dashboard_daily_stats` for the affected date(s). Possible but usually overkill unless you need real-time stored values.

---

## Summary

- The dashboard **already shows** the overall average processing time (average of all items in the current scope).
- You **do not have to** store it in the database; computing on read is correct and often enough.
- If you want it **stored in Supabase**, use the table above and update it either when the dashboard loads (Option A) or via a daily job (Option B).
